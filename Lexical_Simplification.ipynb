{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e29f100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import wordnet as wn\n",
    "from wordfreq import zipf_frequency\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "nb = [x.name() for x in wn.all_synsets()]\n",
    "\n",
    "mwe = []\n",
    "for x in nb:\n",
    "    if '_' in x:\n",
    "        mwe.append(tuple(x.split('.')[0].split('_'))) \n",
    "mwe.append(tuple(x.split('.')[0].split('_')))\n",
    "tokenizer = MWETokenizer(mwe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cdfd7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_simp(s):\n",
    "    s = s.replace('.',' .')\n",
    "    t = tokenizer.tokenize(s.split())\n",
    "    for word in t: # 'I wear a titfer'\n",
    "\n",
    "        if nltk.pos_tag([word])[0][1] == 'NN': # titfer (NN) True\n",
    "            \n",
    "            if zipf_frequency(word, 'en') < 3.00: #should be simplified\n",
    "                w = wn.synsets(word)\n",
    "                hypernym = []\n",
    "                for i in w:\n",
    "                    hypernym.extend(i.hypernyms())\n",
    "\n",
    "                n = re.match(r'^(.+)\\.[a-z]+\\.[0-9]+', w[0].name())\n",
    "                word_f = [((zipf_frequency(n.group(1), 'en'), n.group(1)))]\n",
    "\n",
    "                proposition = []\n",
    "                for j in hypernym:\n",
    "                    name = j.name().replace('_',' ')\n",
    "                    m = re.match(r'^(.+)\\.[a-z]+\\.[0-9]+', name)\n",
    "                    proposition.append(m.group(1))\n",
    "\n",
    "                candidate = []\n",
    "                for k in proposition:\n",
    "                    candidate.append((zipf_frequency(k, 'en'),k))\n",
    "                    \n",
    "                choice = sorted(candidate + word_f, reverse = True)\n",
    "                a = ' '.join(t)\n",
    "                a = a.replace(word, choice[0][1])\n",
    "                a = a.replace('_',' ')\n",
    "                a = a.replace(' .','.')\n",
    "                s = a\n",
    "                #s = s.replace(word, choice[0][1]) # 'hat'\n",
    "    print(s) # 'I wear a hat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d9de4eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a dog and a bike.\n",
      "You board a castle.\n",
      "I love salmon .\n",
      "We see a big and tall man. He is wearing a hat.\n",
      "This is a real retriever !\n",
      "He did an denial of what I said.\n"
     ]
    }
   ],
   "source": [
    "s1 = 'I have a corgi and a bike.'\n",
    "s2 = 'You live in a castle.'\n",
    "s3 = 'I love salmon.'\n",
    "s4 = \"We see a big and tall man. He is wearing a titfer.\"\n",
    "s5 = 'This is a real golden retriever !'\n",
    "s6 = 'He did an abnegation of what I said.' # need a change from \"an\" to \"a\"\n",
    "lexical_simp(s1)\n",
    "lexical_simp(s2)\n",
    "lexical_simp(s3)\n",
    "lexical_simp(s4)\n",
    "lexical_simp(s5)\n",
    "lexical_simp(s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b098e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('dog.n.01').hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1d25b2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('golden_retriever.n.01')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden = wn.synset('golden_retriever.n.01')\n",
    "golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6807c573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('retriever.n.01')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "452faaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fb6d697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function zipf_frequency in module wordfreq:\n",
      "\n",
      "zipf_frequency(word, lang, wordlist='best', minimum=0.0)\n",
      "    Get the frequency of `word`, in the language with code `lang`, on the Zipf\n",
      "    scale.\n",
      "    \n",
      "    The Zipf scale is a logarithmic frequency scale proposed by Marc Brysbaert,\n",
      "    who compiled the SUBTLEX data. The goal of the Zipf scale is to map\n",
      "    reasonable word frequencies to understandable, small positive numbers.\n",
      "    \n",
      "    A word rates as x on the Zipf scale when it occurs 10**x times per billion\n",
      "    words. For example, a word that occurs once per million words is at 3.0 on\n",
      "    the Zipf scale.\n",
      "    \n",
      "    Zipf values for reasonable words are between 0 and 8. The value this\n",
      "    function returns will always be at last as large as `minimum`, even for a\n",
      "    word that never appears. The default minimum is 0, representing words\n",
      "    that appear once per billion words or less.\n",
      "    \n",
      "    wordfreq internally quantizes its frequencies to centibels, which are\n",
      "    1/100 of a Zipf unit. The output of `zipf_frequency` will be rounded to\n",
      "    the nearest hundredth to match this quantization.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(zipf_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14d48f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipf_frequency('dog','en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f87e195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.98"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipf_frequency('golden retriever','en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4fc6f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.99"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipf_frequency('retriever','en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_simp(s):\n",
    "    t = tokenizer.tokenize(s.split())\n",
    "    print(t)\n",
    "    for word in t: # 'I wear a titfer'\n",
    "\n",
    "        if nltk.pos_tag([word])[0][1] == 'NN': # titfer (NN) True\n",
    "            \n",
    "            if zipf_frequency(word, 'en') < 3.00: #should be simplified\n",
    "                w = wn.synsets(word)\n",
    "                print(w)\n",
    "                hypernym = []\n",
    "                for i in w:\n",
    "                    hypernym.extend(i.hypernyms())\n",
    "\n",
    "                n = re.match(r'^(.+)\\.[a-z]+\\.[0-9]+', w[0].name())\n",
    "                word_f = [((zipf_frequency(n.group(1), 'en'), n.group(1)))]\n",
    "\n",
    "                proposition = []\n",
    "                for j in hypernym:\n",
    "                    name = j.name().replace('_',' ')\n",
    "                    print(name)\n",
    "                    m = re.match(r'^(.+)\\.[a-z]+\\.[0-9]+', name)\n",
    "                    proposition.append(m.group(1))\n",
    "\n",
    "                print(proposition)\n",
    "                candidate = []\n",
    "                for k in proposition:\n",
    "                    candidate.append((zipf_frequency(k, 'en'),k))\n",
    "                    \n",
    "                choice = sorted(candidate + word_f, reverse = True)\n",
    "                s = s.replace(word, choice[0][1]) # 'hat'\n",
    "    print(s) # 'I wear a hat'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
